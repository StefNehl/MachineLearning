%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chair of Cyber-Physical-Systems
% Univ.-Prof. Dr. Elmar Rueckert
% Montanuniversität Leoben, Austria
% Latest Update: Feb. 2022
%
% Disclaimer: The materials and source code are for personal use only. The material is intended for educational purposes only. Reproduction of the material for any purposes other than what is intended is prohibited. The content is to be used for educational and non-commercial purposes only and is not to be changed, altered, or used for any commercial endeavor without the express written permission of Professor Rueckert. 
% 
% Original Version by Frits Wenneker, 28/2/17,  License: CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt, a4paper, twocolumn]{article} % 10pt font size (11 and 12 also possible), A4 paper (letterpaper for US letter) and two column layout (remove for one column)

\input{structure.tex} % Specifies the document structure and loads requires packages

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\title{Assignment IV: Bayes'Theorem and Ridge Regression} % The article title

\author{
	\coursetitle{Exercises in Machine Learning (190.013), SS2022}
	\authorstyle{Stefan Nehl\textsuperscript{1}} % Authors
	\newline\newline % Space before institutions
	\textsuperscript{1}\textit{stefan-christopher.nehl@stud.unileoben.ac.at, MNr: 00935188}, \institution{Montanuniversität Leoben, Austria}\\ % Institution 1
	\newline\submissiondate{\today} % Add a date here
}

% Example of a one line author/institution relationship
%\author{\newauthor{John Marston} \newinstitution{Universidad Nacional Autónoma de México, Mexico City, Mexico}}


%----------------------------------------------------------------------------------------

\begin{document}
\input{python_code.tex} % To print Python code

\maketitle % Print the title

\thispagestyle{firstpage} % Apply the page style for the first page (no headers and footers)

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\lettrineabstract{In the fourth assignment, I had to solve three different task. First, calculate the probability for a positive test results with the Bayes' Theorem, next describe the ridge regression and derive the weight update for with the least squares regression and last implement the ridge regression. The implementation of the ridge regression also includes testing the model and plotting it's results.}

%----------------------------------------------------------------------------------------
%	REPORT CONTENTS
%----------------------------------------------------------------------------------------

\section{Task 1: Bayes'Theorem}
The Bayes'Theorem is a mathematical formula which describes the probability of an event. Furthermore, it is used for calculating conditional probabilities. \citep{bayesTheoremHist}

\[
p(A|B) = \frac{p(B|A)p(A)}{p(B)}
\]

\citep{bookMachineLearning}

I used this formula to calculate the probability to be infected with SARS CoV2 and having a positive test result of an antigen test. Let A $\in$ [infected, non-infected] the event, which defines if a person is infected or not, and B $\in$ [+,-] the event, which defines the result of the antigen test.

\subsection{Implementation}
First, I created the following variables with the values.

\begin{table}[htbp]
    \label{tab:alphaBetaParameters}
	\caption{Variables and Values}
	\centering
	\begin{tabular}{llr}
		\cmidrule(r){1-2}
		name & value \\
		\midrule
		\textit{populationAustria} & 9095538 \\
		\textit{activeCases} & 441098 \\
		\textit{covTestSensitivity} & 0.971 \\
		\textit{covTestSpecific} & 0.995 \\
		\bottomrule
	\end{tabular}
\end{table}
First, I set the variable for \textit{p(+|inf)} to the value of \textit{covTestSensitivity} and the variable for \textit{p(-|nInf)} tp the value of \textit{covTestSpecific}.
Next, I calculated the value for \textit{p(inf)}, \textit{p(nInf} and stored the values in the variables 
\textit{pInfected} and \textit{pNotInfected}. 
\[
p(inf) = \textit{activeCases} / \textit{populationAustria}
\]
\[
p(nInf) = 1 -  p(inf)
\]
The variable \textit{p(inf)} defines the value for the probability to be infected with covid and \textit{p(nInf)} not. 
Furthermore, the abbreviation for infected is \textit{inf} and for non infected \textit{nInf}.The abbreviation for having a positive test result is $+$ and for a negative test result $-$.
Next, I initialized the following variables and calculated there values with the following formulas.
\[
p(nInf \& -) = p(nInf) * p(-|non-infected)
\]
\[
p(-) = p(inf \& -) + p(nInf \& -)
\]
\[
p(nInf \& +) = p(nInf) - p(nInf\& -)
\]
\[
p(+) = p(inf \& +) + p(nInf \& +)
\]
\[
p(-|inf) = \frac{p(inf \& -)}{p(-)}
\]
\[
p(+|nInf) = \frac{p(nInf\& +)}{p(nInf)}
\]
Last, I used the Bayes'Theorem to calculate the $p(infected|+)$ value.
\[
p(inf|+) = \frac{p(+|inf) * p(inf)} {p(nInf)}
\]


\subsection{Result and Conclusion}
The results of the calculation is displayed in Table 2.
\begin{table}[htbp]
    \label{tab:alphaBetaParameters}
	\caption{Results}
	\centering
	\begin{tabular}{llr}
		\cmidrule(r){1-2}
		name & value \\
		\midrule
		\textit{p(-|inf)}  & 00.15\% \\
		\textit{p(+|nInf)} & 02.90\% \\
		\textit{p(inf)}    & 04.85\% \\
		\textit{p(nInf)}   & 95.15\% \\
		\textit{p(+)}      & 07.47\% \\
		\textit{p(inf|+)}  & 63.05\% \\
		\bottomrule
	\end{tabular}
\end{table}
The result for \textit{p(inf|+)} is $0.630525 \approx 63.05\%$. Which means there is a $63.05\%$ chance to be infected with covid and get a positive test result. The implemented code can be found in the appendix of this paper.

\section{Task 2: Ridge Regression}
Ridge regression is used for parameter estimation to address the collinearity problem in multiple linear regression. 
\citep{ridgeRegression} The Ridge Regression adds the quadratic regularization term 
$\frac{\lambda}{2}$
$(\boldsymbol{\omega}\textsuperscript{T}\boldsymbol{\omega})$ to the objective $\textbf{J}_{LS}$.
\citep{bookMachineLearning}

\subsection{Derivation of the Least Squares Solution}
For the derivation of the least squares I defined the vectors $\textbf{y} \in \mathbb{R}$,
$\textbf{A} \in \mathbb{R}^{nxM}$ and
$\textbf{$\omega$} \in \mathbb{R}^{M}$ where M is the dimension and n the number of samples.

\[
\frac{\partial \textbf{$J_{LS}$}}{\partial \boldsymbol{\omega}} = 
\frac{\partial}{\partial \boldsymbol{\omega}}
\{1/2\sigma^{-2}
(\textbf{y} - \textbf{A}\boldsymbol{\omega})^{T}
(\textbf{y} - \textbf{A}\boldsymbol{\omega})
\}
\]
After the partial deviation we receive the following equation. 
\[
\frac{\partial \textbf{$J_{LS}$}}{\partial \boldsymbol{\omega}} = 
1/2\sigma^{-2}
(-2 \textbf{y}^{T} \textbf{A} + 2 \boldsymbol{\omega}^{T}\textbf{A}^{T}\textbf{A})
\]
I set this equation to zero to calculate the least square solution. 
\[
\frac{\partial \textbf{$J_{LS}$}}{\partial \boldsymbol{\omega}} = 0,
\]
\[
1/2\sigma^{-2}
(-2 \textbf{y}^{T} \textbf{A} + 2 \boldsymbol{\omega}^{T}\textbf{A}^{T}\textbf{A}) = 0,
\]
\[
1/2\sigma^{-2}
(-2 \textbf{y}^{T} \textbf{A} + 2 \boldsymbol{\omega}^{T}\textbf{A}^{T}\textbf{A}) = 0,
\]
\[
-\textbf{y}^{T} \textbf{A} + \boldsymbol{\omega}^{T} \textbf{A}^{T}\textbf{A}\boldsymbol{w} = 0,
\]
\[
 \boldsymbol{\omega} = (\textbf{A}^{T}\textbf{A})^{-1}\textbf{A}^{T}\textbf{y}.
\]
\citep{bookMachineLearning}
Important here is, that the matrix \textbf{A} has a full rank and is invertible. If this is not the case I would use 
the Moore–Penrose inverse which is described in the following formula. 
\[
\textbf{A}^{+} = (\textbf{A}^{T}\textbf{A})^{-1}\textbf{A}{T}.
\]
\citep{bookMachineLearning}


\section{Task 3: Implementation of Ridge Regression}
The last task was to implement the ridge regression for a given dataset. The dataset includes longitude and latitude of a map with the corresponding temperature data. 
\subsection{Import Data and Implementation}
For the implementation I first created the abstract class \textit{Regression} which includes the abstract methods \textit{importData}, \textit{generateTrainingSubset}, \textit{computeLinearRidgeRegression}, \textit{testModel}, 
\textit{computeError}, \textit{plotError}, \textit{plotHeatMap}, \textit{computMeanOfError}
Then i created the class \textit{RidgeRegression} which implements those methods and has the parameter \textit{trainStep} which indicates the size of the training data. For importing the data I used the scipy.io library which is able to read \textit{MatLab} files and load this data. I used only the first dataset of the time series data to create the model. The method \textit{generateTrainingSubset} creates the training data with the parameter \textit{trainStep}. The parameter \textit{trainStep} defines the size of the training set. For example, if the value is set to 4 every 4. values is used for the calculation of the weight values. 

\subsection{Ridge Regression}
For the Implementation of the Ridge Regression calculation I added the method \textit{computeLinearRidgeRegression} and made the calculation. I followed the formula from chapter 2 and used the \textit{numpy} library to do the matrix calculations. I added a helper method which I used to create the feature vector for the calculation. The method is name \textit{createFeatureVector} and takes the parameter \textit{x}. The parameter \textit{x} is the vector of the current y-value. In our case it's a two dimensional vector with the longitude and latitude. I augmented this vector and created the new vector \textit{featureVector} which is a three dimensional vector. The first dimension contains a 1, the second the latitude and the third the longitude. This vector was then returned from the method. After the creation of the feature vectors, the method \textit{computeLinearRidgeRegression} finishes it's calculations and returns the weight vector.  

\subsection{Plotting}

\subsection{Results}
Figure 1 shows the gauss distribution for one dimension. It displays the values distribution and the frequencies of those values. The orange line displays the gauss distribution itself.


\subsection{Conclusion}
The implementation of the abstract class was straightforward. For the other classes I made some changes. I moved the classes to separate files to handle them better. Unfortunately, I was not able to create a satisfying plot for the gauss distribution for two dimensions. The whole code is in the appendix of this paper. 

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\printbibliography[title={Bibliography}] % Print the bibliography, section title in curly brackets

%----------------------------------------------------------------------------------------

\section*{APPENDIX}
%\onecolumn\lstinputlisting{../Task1_BayesTheorem.py}
%\onecolumn\lstinputlisting{../Task3_RidgeRegression.py}
%\onecolumn\lstinputlisting[]{../../Modules/RidgeRegression.py}





\end{document}
